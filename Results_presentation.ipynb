{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58f55da",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The goal of this project is to test how good different models are at generating summaries.  \n",
    "A good summary should keep the most important information from the text while staying short and easy to read.  \n",
    "\n",
    "To check this, we compare the summaries from several models (like **BART**, **LED**, **T5**, **Pegasus**, **GPT-2**, and **Phi-3**) with:  \n",
    "1. **A human-made summary** – to see how close the models are to what a person would write.  \n",
    "2. **The original text** – to see how much important information the models actually keep.  \n",
    "\n",
    "We use two types of metrics:  \n",
    "- **BERTScore** → measures similarity in meaning between sentences.  \n",
    "- **ROUGE (1, 2, L)** → measures word overlap (how many words or sequences of words are shared).  \n",
    "\n",
    "By comparing both perspectives, we can figure out:  \n",
    "- Which models create the most human-like summaries.  \n",
    "- Which models best capture the key ideas from the original text.  \n",
    "\n",
    "This helps us better understand the strengths and weaknesses of each summarization model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b808d6",
   "metadata": {},
   "source": [
    "### Import libraries and display settings\n",
    "Import the necessary libraries and adjust pandas display options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c95a2dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "\n",
    "#from evaluate import load\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "from bert_score import BERTScorer\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b3c19",
   "metadata": {},
   "source": [
    "### Import data\n",
    "Import the required data for grading.\n",
    "There are two df_predict, one for comparing the untrained (not fine-tuned) models, the other to compare the trained (fine-tuned) models that were selected as the best based on the results from the untrained models.\\\n",
    "I choosed the 3 models performing the best according to the bertscore, those were phi-3, bart-large-cnn and flan-t5-base (phi-3 wasn't fine-tuned because of a lack of resources for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c551c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_json('data/lotm_clean_dataset.json')\n",
    "\n",
    "df_predict = pd.read_json('data/model_comparison.json') #untrained models\n",
    "\n",
    "#df_predict = pd.read_json('data/Trained_model_comparison.json') #trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89788b15",
   "metadata": {},
   "source": [
    "### Prepare DataFrames for scoring summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a069b53c",
   "metadata": {},
   "source": [
    "Create a DataFrame (df_benchmark) to store evaluation scores (ROUGE and BERTScore) between generated summaries and the originals texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e27a1832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    num_chp             model                                  predicted_summary                                      original_text\n",
      "0         2       gpt2-medium   to find out if he could fire the revolver aga...  After confirming his plan, Zhou Mingrui immedi...\n",
      "1      1379       gpt2-medium   it was still not enough.\\n\"You think that I w...  More than a thousand Amons each committed \"The...\n",
      "2      1347       gpt2-medium  \\n\"I'll do everything in my power to help you,...  Blue Mountain Island, within a primitive fores...\n",
      "3      1238       gpt2-medium   still know the reason.\"\\nCattleya nodded and ...  Upon hearing Cattleya's words, Queen Mystic Be...\n",
      "4       784       gpt2-medium   to see if she could see anything.\\nShe saw a ...  100 Böklund Street, in a corner of the garden ...\n",
      "..      ...               ...                                                ...                                                ...\n",
      "67     1117  handmade_summary  As the flames flicker, Derrick and company enc...  In the past, Rose Redemption could be called t...\n",
      "68     1234  handmade_summary  As the Shaman King Klarman faces Emlyn White's...  The silver-black, three-tiered accessory box w...\n",
      "69     1238  handmade_summary  Klein remains in Sefirah Castle, reviewing the...  Upon hearing Cattleya's words, Queen Mystic Be...\n",
      "70     1347  handmade_summary  As Klein stands before Adam in the grand, holy...  Blue Mountain Island, within a primitive fores...\n",
      "71     1379  handmade_summary  The curtain shielding the Antigonus palace van...  More than a thousand Amons each committed \"The...\n",
      "\n",
      "[72 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "### df for comparing summaries with text\n",
    "df_benchmark = pd.DataFrame()\n",
    "\n",
    "df_benchmark['num_chp'] = df_predict['num_chp']\n",
    "df_benchmark['model'] = df_predict['model']\n",
    "df_benchmark['predicted_summary'] = df_predict['summary']\n",
    "\n",
    "for index, row in df_test[df_test['num_chp'].isin(df_predict['num_chp'])].iterrows():\n",
    "    df_benchmark.loc[len(df_benchmark)] = [row['num_chp'],\"handmade_summary\",row['summary']]\n",
    "\n",
    "df_benchmark['original_text'] = df_benchmark.apply(lambda row: df_test.iloc[row.num_chp][\"text\"], axis=1)\n",
    "print(df_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd244a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = df_benchmark[\"original_text\"].tolist()\n",
    "generated_summary = df_benchmark[\"predicted_summary\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59716e6e",
   "metadata": {},
   "source": [
    "Create a DataFrame (df_grading) to store evaluation scores (ROUGE and BERTScore) between generated summaries and the handmade summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ae80a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### df for comparing generated summaries with handmade summary\n",
    "df_grading = pd.DataFrame()\n",
    "\n",
    "df_grading['num_chp'] = df_predict['num_chp']\n",
    "df_grading['model'] = df_predict['model']\n",
    "df_grading['predicted_summary'] = df_predict['summary']\n",
    "df_grading['expected_summary'] = df_grading.apply(lambda row: df_test.iloc[row.num_chp][\"summary\"], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e1c6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_summary = df_grading[\"predicted_summary\"].tolist()\n",
    "expected_summary = df_grading[\"expected_summary\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d818061c",
   "metadata": {},
   "source": [
    "### Compute scores on both DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae336881",
   "metadata": {},
   "source": [
    "Implement Bertscore on both DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f18a8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "scorer = BERTScorer(lang=\"en\", rescale_with_baseline=False)\n",
    "\n",
    "P, R, F1 = scorer.score(predicted_summary, expected_summary)\n",
    "\n",
    "# Add results to DataFrame\n",
    "df_grading[\"bertscore_P\"] = P.tolist()\n",
    "df_grading[\"bertscore_R\"] = R.tolist()\n",
    "df_grading[\"bertscore_F1\"] = F1.tolist()\n",
    "\n",
    "P_b, R_b, F1_b = scorer.score(original_text, generated_summary)\n",
    "\n",
    "# Add results to DataFrame\n",
    "df_benchmark[\"bertscore_P\"] = P_b.tolist()\n",
    "df_benchmark[\"bertscore_R\"] = R_b.tolist()\n",
    "df_benchmark[\"bertscore_F1\"] = F1_b.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2572e971",
   "metadata": {},
   "source": [
    "Implement Rougescore on both DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e09d8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de4402f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rouge(row):\n",
    "    scores = scorer.score(\n",
    "        row[\"expected_summary\"],   # reference\n",
    "        row[\"predicted_summary\"]   # candidate\n",
    "    )\n",
    "    return (\n",
    "        scores[\"rouge1\"].fmeasure,\n",
    "        scores[\"rouge2\"].fmeasure,\n",
    "        scores[\"rougeL\"].fmeasure,\n",
    "    )\n",
    "\n",
    "# Apply row by row\n",
    "df_grading[[\"rouge1\", \"rouge2\", \"rougeL\"]] = df_grading.apply(\n",
    "    compute_rouge, axis=1, result_type=\"expand\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8b0f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rouge_for_benchmark(row):\n",
    "    scores = scorer.score(\n",
    "        row['original_text'],   # reference\n",
    "        row['predicted_summary']   # candidate\n",
    "    )\n",
    "    return (\n",
    "        scores[\"rouge1\"].fmeasure,\n",
    "        scores[\"rouge2\"].fmeasure,\n",
    "        scores[\"rougeL\"].fmeasure,\n",
    "    )\n",
    "\n",
    "# Apply row by row\n",
    "df_benchmark[[\"rouge1\", \"rouge2\", \"rougeL\"]] = df_benchmark.apply(\n",
    "    compute_rouge_for_benchmark, axis=1, result_type=\"expand\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce86a0a",
   "metadata": {},
   "source": [
    "### Display grading results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bcfb7c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score : summary vs handmade summary\n",
      "                                    bertscore_P  bertscore_R  bertscore_F1    rouge1    rouge2    rougeL\n",
      "model                                                                                                   \n",
      "allenai/led-base-16384                 0.809921     0.817721      0.813758  0.277321  0.035704  0.139669\n",
      "facebook/bart-large-cnn                0.813301     0.819481      0.816366  0.305096  0.038361  0.154470\n",
      "google/flan-t5-base                    0.802704     0.812035      0.807326  0.270229  0.030472  0.138510\n",
      "google/pegasus-xsum                    0.766373     0.802612      0.783905  0.227252  0.026955  0.143147\n",
      "gpt2-medium                            0.797691     0.805384      0.801427  0.222925  0.023282  0.124996\n",
      "microsoft/phi-3-mini-128k-instruct     0.845819     0.826555      0.836044  0.275925  0.048339  0.146655\n",
      "t5-large                               0.736195     0.793587      0.763597  0.154104  0.018911  0.103453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_global_score = df_grading.groupby([\"model\"]).agg(\n",
    "    bertscore_P=('bertscore_P', 'mean'),\n",
    "    bertscore_R=('bertscore_R', 'mean'),\n",
    "    bertscore_F1=('bertscore_F1', 'mean'),\n",
    "    rouge1=('rouge1', 'mean'),\n",
    "    rouge2=('rouge2', 'mean'),\n",
    "    rougeL=('rougeL', 'mean')\n",
    ")\n",
    "print(\"score : summary vs handmade summary\")\n",
    "print(df_global_score)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bcfac7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score : summary vs text\n",
      "                                    bertscore_P  bertscore_R  bertscore_F1    rouge1    rouge2    rougeL\n",
      "model                                                                                                   \n",
      "allenai/led-base-16384                 0.806687     0.815557      0.811064  0.146817  0.040200  0.077072\n",
      "facebook/bart-large-cnn                0.807059     0.816831      0.811905  0.146754  0.039599  0.076553\n",
      "google/flan-t5-base                    0.796246     0.803600      0.799895  0.116140  0.027620  0.066004\n",
      "google/pegasus-xsum                    0.786850     0.769717      0.778068  0.120223  0.029950  0.074981\n",
      "gpt2-medium                            0.796492     0.808278      0.802274  0.129006  0.028298  0.071833\n",
      "handmade_summary                       0.804837     0.822709      0.813660  0.118834  0.027364  0.065481\n",
      "microsoft/phi-3-mini-128k-instruct     0.797912     0.832487      0.814800  0.072698  0.021526  0.045544\n",
      "t5-large                               0.778542     0.740661      0.758976  0.041377  0.012564  0.032388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_benchmark_score = df_benchmark.groupby([\"model\"]).agg(\n",
    "    bertscore_P=('bertscore_P', 'mean'),\n",
    "    bertscore_R=('bertscore_R', 'mean'),\n",
    "    bertscore_F1=('bertscore_F1', 'mean'),\n",
    "    rouge1=('rouge1', 'mean'),\n",
    "    rouge2=('rouge2', 'mean'),\n",
    "    rougeL=('rougeL', 'mean')\n",
    ")\n",
    "print(\"score : summary vs text\")\n",
    "print(df_benchmark_score)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c393b8",
   "metadata": {},
   "source": [
    "We display below the summaries generated by the different models of the first text of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73e293c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected summary of chapter 2: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Zhou Mingrui's gaze falls upon a dessicated corpse-like reflection in the dressing mirror, leaving him reeling in fear. Despite his initial terror, he tries to calm himself and inspects his body, finding his wounds to be grievous but his vitality strong. He attempts to examine his head injury but is hindered by the dim lighting. As he searches for a solution, a memory fragment from his past life as Klein Moretti surfaces, reminding him of the gas lamp's capabilities. He finds the lamp on the wall and attempts to light it, but it doesn't work at first. After recalling his brother Benson's resourcefulness in installing gas pipes, Zhou Mingrui discovers a gas meter and uses a copper penny to activate it, finally illuminating the room with a warm glow. With the darkness receded, Zhou Mingrui inspects his wound again, finding it to be rapidly healing. He attributes this to the restorative effects of transmigration. Feeling relieved, he decides to clean up the blood stains on his head and ventures out into the dark corridor, where the crimson moonlight casts eerie silhouettes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--gpt2-medium summary of chapter 2--\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       " to find out if he could fire the revolver again!\n",
       "If he could do it, he would then have the chance to try to assassinate his brother again!\n",
       "If he failed, then he would not be able to kill his brother again!\n",
       "If he succeeded, he would not be able to kill his brother again!\n",
       "Zhou Mingrui finally opened his eyes.\n",
       "He was facing a wall.\n",
       "At the side of the wall was a small hole that was about two inches wide.\n",
       "That hole was the one that had been drilled through Zhou Mingrui's skull.\n",
       "The hole had been filled with a thick layer of blood.\n",
       "Zhou Mingrui did not know why the hole had been filled, but he knew that it was because the bullet had pierced through his head.\n",
       "Zhou Mingrui was a man with a long and illustrious career.\n",
       "He had been a deputy of the People's Republic of China for many years, and he had been a member of the Supreme People's Assembly of the People's Republic of China for a long time.\n",
       "He had also served as the deputy head of the Central Military Commission.\n",
       "He had been a member of the People's Liberation Army for over 20 years, and he had been a member of the People's Liberation Army for over a decade.\n",
       "He had been a member of the People's Republic of China for over 15 years, and he had been a member of the People's Republic of"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--microsoft/phi-3-mini-128k-instruct summary of chapter 2--\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "Zhou Mingrui, experiencing a series of bad luck events, recalled performing a luck enhancement ritual involving placing four portions of staple food in his room and taking four counterclockwise steps while chanting blessings. After his transmigration, which occurred overnight, he contemplated the possibility that his transmigration could be a result of the ritual and decided to repeat it in the hopes of returning.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--google/flan-t5-base summary of chapter 2--\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Zhou Mingrui drew back in fear at the sight that greeted him. It was as though the person in the dressing mirror was not himself, but a dessicated corpse. How could a person with such grievous wounds be still alive Zhou Mingrui was not a rash person who did not think of the consequences of taking on debt. He was a literate and had worked for several years. He insisted on creating conducive studying conditions for Klein even if it meant taking on debt. Zhou Mingrui's transmigration to China began with a single penny, which was only minted and circulated after King George III ascended to the throne. After flipping the coin-which was only minted and circulated after King Zhou Mingrui would be able to hear the sound of the water from the sink, but if the water gushed too loudly, Mr. Franky would be able to hear the sound of the water from the sink. Zhou Mingrui had a rough idea of how Klein had died. He was in no hurry to verify his guess. Instead, he wiped away the blood stains and cleaned up the'scene' beneath the desk. Zhou Mingrui's right hand was subconsciously pulling out the revolver's cylinder and s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--facebook/bart-large-cnn summary of chapter 2--\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Zhou Mingrui's brother, Benson, installed gas pipes in his apartment to improve the apartment's standards. Zhou's brother wanted to create conducive studying conditions for Klein Moretti even if it meant taking on debt. Zhou took out a coin from his pocket and inserted it into the gas meter's vertical'mouth' The penny fell to the bottom of the meter, producing a short but melodious mechanical rhythm. Zhou then touched his exposed skin. Beneath the slight coldness was flowing warmth. It was as though the person in the dressing mirror was not himself, but a dessicated corpse. Zhou was shocked to see the penetrating wound and dark red blood stains in the mirror. He was still alive! He was alive! How could a person with such grievous wounds be still alive!? Zhou was stunned to see that he was alive. He had been injured! He had just been hit in the head with a coin.                A fire plume ignited and rapidly grew. Bright light first occupied the internals of a wall lamp before penetrating the transparent glass, blanketing the Zhou Mingruo tried a luck enhancement ritual before dinner today. The ritual was extremely simple, without any basic foundation requirements. The first step required him to sincerely chant ‘Blessings Stem From The Immortal Lord of Heaven and Earth' The second step was to silently chant, 'Blessing Stem from The Sky Lord of heaven and earth' The third step"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--google/pegasus-xsum summary of chapter 2--\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Zhou Mingrui had no choice but to use his savings to buy a gas meter for the Loen Kingdom's capital city, but he had no choice but to use his savings to buy a gas meter for the Loen Kingdom's capital city, and he had no choice but to use his savings to buy a gas meter for the Loen Kingdom's capital city, and he had no choice but to use his savings to buy a gas meter for the Loen Kingdom's capital city, and he had no choice but to use his savings to buy a gas meter for the Loen Kingdom's capital city, and he had no choice but to use his savings to buy a gas meter for the Loen Kingdom's capital city, and he had no choice but to use his savings to buy a gas meter for the Loen Kingdom's capital city, and he had no choice but to use his savings to buy a gas meter for the Loen Kingdom's capital city, and he had no choice but to use his savings to buy a gas meter for the Loen Kingdom's capital city, and he had no choice but to use his savings to buy a gas meter for the Loen Kingdom's capital city, and he had no choice but to use his savings to buy a gas meter for the Loen Kingdom's capital city, and he had no choice but to use his savings to buy a gas meter for the Loen Kingdom's"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--t5-large summary of chapter 2--\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "a Hail Mary! He had to attempt a Hail Mary! He had to attempt a Hail Mary! He had to attempt a Hail Mary! He had to attempt a Hail Mary! He had to attempt a Hail Mary! paragraph without bullet points, there was not a single blood stain on his temple.. The coin was a copper penny.. The coin was engraved with a portrait of a crown-wearing man on the back., there.......,...........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................,,,,............................................................................................................................................................................................,?......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--allenai/led-base-16384 summary of chapter 2--\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Zhou Mingrui looked around the room. He saw that there was no one in the room with a warm glow.Zhou Mingrui reeled back in fear at the sight that greeted him. It was as though the person in the dressing mirror was not himself, but a dessicated corpse.Zhou Mingrui looked around the room. \"How could a person with such grievous wounds be still alive!?”He turned his head in disbelief again and checked the other side. Even though he was a distance away and the lighting was poor, he could still see the penetrating wound and dark red blood stains.Zhou Mingrui looked around the room.\"This...\"Zhou Mingrui drew a deep breath as he tried hard to calm himself. \"This is the most important thing in the world.\"He reached out to press his left chest and sensed his racing heart that exuded immense vitality. \"This is the most important thing in the world.\"He then touched his exposed skin. Beneath the slight coldness was flowing warmth. \"This is the most important thing in the world.\"\"The restorative effects that transmigration brings?\" Zhou Mingrui curled up the right corner of his mouth as he muttered silently. \"This is the most important thing in the world.\"\"What's happening?\" he muttered with a frown. He planned to inspect his head injury seriously once more. \"This is the most important thing in the world.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import display, Markdown\n",
    "#take a look at the summaries of the first text\n",
    "test_chp = min(df_predict['num_chp'])\n",
    "\n",
    "my_df = df_predict[df_predict['num_chp']==test_chp]\n",
    "\n",
    "print(f\"Expected summary of chapter {test_chp}: \")\n",
    "display(Markdown(df_test[df_test[\"num_chp\"] == test_chp][\"summary\"].tolist()[0]))\n",
    "print(\"\")\n",
    "\n",
    "for model_ in my_df['model']:\n",
    "    print(f\"--{model_} summary of chapter {test_chp}--\")\n",
    "    display(Markdown(my_df.loc[my_df['model']== model_, 'summary'].iloc[0]))\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
